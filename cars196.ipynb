{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aofekiko/Cars196-E2E-CNN/blob/main/cars196.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Project - Basics of deep learning\n",
        "Hello dear students,<br> This is the template notebook. Please copy it into your drive.\n",
        "\n",
        "---\n",
        "<br>\n",
        "\n",
        "### Name and ID:\n",
        "Student 1:\n",
        "<br>\n",
        "Student 2:"
      ],
      "metadata": {
        "id": "6-W8kOgHZUhz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/20733/logos/header.png?t=2020-05-14-08-44-45\">"
      ],
      "metadata": {
        "id": "S17rzhsdZem0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "buJeccWRZX26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "52FrgSEzQYWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from keras.utils import load_img\n",
        "from keras.preprocessing import image\n",
        "!pip install -U --no-cache-dir gdown --pre\n",
        "!gdown --id 1DS_5kLbzYYzMWtp1WP3x_hxtRBhroJID"
      ],
      "metadata": {
        "id": "DVQDuMr52due"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "Cars196 - 196 different classes of vehicles"
      ],
      "metadata": {
        "id": "1hxROtsyjWPW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download Data"
      ],
      "metadata": {
        "id": "IlSkIXYtYQi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "cars196 = tfds.load('Cars196', as_supervised=True, shuffle_files=True, with_info=True, data_dir=\".\")"
      ],
      "metadata": {
        "id": "pOr9XYNO4QS1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dictionary of the labels - maps between the label (int) number and the vehicle model (str)"
      ],
      "metadata": {
        "id": "6LpjqcRTZ2gm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_dic = pd.read_csv('labels_dic.csv', header=None, dtype={0: str}).set_index(0).squeeze().to_dict()"
      ],
      "metadata": {
        "id": "wYeQz_hntvY2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function - Plot Single Example\n",
        "This function receives an image and a label and it will display it on a plot"
      ],
      "metadata": {
        "id": "UxFQGdYzYffQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_single_example(image, label, label_dic=label_dic):\n",
        "  car_model_by_label = label_dic[str(label)]\n",
        "  plt.title(f'Image Label: {car_model_by_label} ({label})')\n",
        "  plt.imshow(image)\n"
      ],
      "metadata": {
        "id": "zHABcIRJZOTC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "5trNlNNHawd6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split Dataset\n",
        "Train set contains 8041 examples<br>\n",
        "Test set contains 8144 examples<br>\n",
        "**It is allowed to change the ratio between the data sets.**\n"
      ],
      "metadata": {
        "id": "t6hlzURV498F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cars_train=cars196['train']\n",
        "#cars_test=cars196['test']\n",
        "\n",
        "#[cars_train, cars_test], cars_info = tfds.load('Cars196',  split=[\"train\", \"test\"], as_supervised=True, shuffle_files=True, with_info=True, data_dir=\".\")\n",
        "\n",
        "[cars_train, cars_test] = tfds.load('Cars196',  split=[\"train[:90%]+test[:90%]\", \"train[90%:100%]+test[90%:100%]\"], as_supervised=True, shuffle_files=True, data_dir=\".\")\n",
        "print(len(cars_test))\n",
        "print(len(cars_train))"
      ],
      "metadata": {
        "id": "HYsfRMHu5Ew8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2c8843b-317c-4feb-e199-d221e6d6fd0f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1618\n",
            "14567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resize the data"
      ],
      "metadata": {
        "id": "SHCuGzL6HK_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "height, width = 256, 256  # Previously: 256, 256 # Inputs divisable by 16 or 8 for better tensor core efficiency (https://www.tensorflow.org/guide/gpu_performance_analysis#1_enable_mixed_precision)\n",
        "\n",
        "#def resize_and_rescale(image, label):\n",
        "#  image = tf.cast(image, tf.float32)\n",
        "#  image = tf.image.resize(image, [height, width])\n",
        "#  image = (image / 255.0)\n",
        "#  return image, label\n",
        "\n",
        "def one_hot_encode(image, label):\n",
        "  label = tf.one_hot(label, 196)\n",
        "  return image, label\n",
        "\n",
        "\n",
        "#size = (height, width)\n",
        "#cars_train = cars_train.map(resize_and_rescale).map(one_hot_encode)\n",
        "#cars_test = cars_test.map(resize_and_rescale).map(one_hot_encode)\n",
        "\n",
        "# Parallel mapping to get rid of the input performance bottleneck\n",
        "cars_train = cars_train.map(lambda x, y: (tf.image.resize_with_pad(x, height, width), y),num_parallel_calls=tf.data.AUTOTUNE)\n",
        "cars_test = cars_test.map(lambda x, y: (tf.image.resize_with_pad(x, height, width), y),num_parallel_calls=tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "EBtJDdIqCZxp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "526c0cf7-936c-4b9c-85f2-f1e0e3249164"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example\n",
        "Random example from the data set"
      ],
      "metadata": {
        "id": "DiXJ1wJCYtgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#image, label = cars_train.as_numpy_iterator().next()\n",
        "#plot_single_example(image, label)\n",
        "\n",
        "#tfds.visualization.show_examples(cars_train, cars_info)"
      ],
      "metadata": {
        "id": "ygZijXWwbL6w"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64 #64\n",
        "\n",
        "#def augment_func(image, label):\n",
        "#    image = tf.image.resize_with_crop_or_pad(image, height + 6, width + 6)\n",
        "#    image = tf.image.random_crop(image, size=[height, width, 3])\n",
        "#    image = tf.image.random_flip_left_right(image)\n",
        "#    image = tf.image.random_hue(image, 0.2)\n",
        "#    image = tf.image.random_contrast(image, 0.5, 2)\n",
        "#    image = tf.image.random_saturation(image, 0, 2)\n",
        "#    return image, label\n",
        "\n",
        "\n",
        "\n",
        "#cars_train = cars_train.cache().map(augment_func).shuffle(100).batch(batch_size).prefetch(buffer_size=10)\n",
        "cars_train = cars_train.batch(batch_size, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
        "cars_test = cars_test.batch(batch_size, drop_remainder=True).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "S5X095JyZaGY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Mixed precision for better performance (https://www.tensorflow.org/guide/mixed_precision)\n",
        "# With AMP: \n",
        "#   Test 1 - 295s\n",
        "#   Test 2 - 388s\n",
        "#   Test 3 - 330s\n",
        "#   Avg - 337.6\n",
        "# Without AMP = \n",
        "#   Test 1 - 288s\n",
        "#   Test 2 - 500s\n",
        "#   Test 2 - 494s\n",
        "#   Avg - 427\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Rescaling(1. / 255, input_shape=(height, width, 3)),\n",
        "        tf.keras.layers.RandomFlip(\"horizontal\"), #NEW\n",
        "        tf.keras.layers.RandomRotation(0.2), #NEW\n",
        "        tf.keras.layers.RandomContrast(0.2), #NEW\n",
        "        #tf.keras.layers.RandomCrop(height, width, 3), #NEW Dataset does not include cropped or uncentered view of cars\n",
        "        tf.keras.layers.RandomZoom(0, .2), #NEW\n",
        "        tf.keras.layers.RandomBrightness(0.2), # NEW\n",
        "        tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(),\n",
        "        tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(),\n",
        "        tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(),\n",
        "        tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(),\n",
        "        tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(),\n",
        "        tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu'), \n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(),\n",
        "        #tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu'), #NEW\n",
        "        #tf.keras.layers.BatchNormalization(), #NEW\n",
        "        #tf.keras.layers.MaxPooling2D(), #NEW\n",
        "        tf.keras.layers.Flatten(),\n",
        "        #tf.keras.layers.Dropout(0.5),\n",
        "        #tf.keras.layers.Dense(256, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(196, activation='softmax', dtype='float32') # Force datatype to be 32 due to enabling mixed precision (Nvidia AXP)\n",
        "    ])\n",
        "\n",
        "##https://www.kaggle.com/code/blurredmachine/alexnet-architecture-a-complete-guide/notebook\n",
        "\n",
        "#model=tf.keras.models.Sequential([\n",
        "#    tf.keras.layers.Rescaling(1. / 255, input_shape=(height, width, 3)),\n",
        "#    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "#    tf.keras.layers.RandomRotation(0.2),\n",
        "#    tf.keras.layers.RandomContrast(0.5, 2),\n",
        "#    #tf.keras.layers.RandomCrop(height, width, 3),\n",
        "#    tf.keras.layers.RandomZoom(.5, .2),\n",
        "#    tf.keras.layers.Conv2D(filters=128, kernel_size=(11,11), strides=(4,4), activation='relu'),\n",
        "#    tf.keras.layers.BatchNormalization(),\n",
        "#    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "#    tf.keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "#    tf.keras.layers.BatchNormalization(),\n",
        "#    tf.keras.layers.MaxPool2D(pool_size=(3,3)),\n",
        "#    tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "#    tf.keras.layers.BatchNormalization(),\n",
        "#    tf.keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "#    tf.keras.layers.BatchNormalization(),\n",
        "#    tf.keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "#    tf.keras.layers.BatchNormalization(),\n",
        "#    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "#    tf.keras.layers.Flatten(),\n",
        "#    tf.keras.layers.Dense(256,activation='relu'),\n",
        "#    #tf.keras.layers.Dropout(0.5),\n",
        "#    tf.keras.layers.Dense(256,activation='relu'),\n",
        "#    #tf.keras.layers.Dropout(0.5),\n",
        "#    tf.keras.layers.Dense(196,activation='softmax')  \n",
        "#])\n",
        "\n",
        "#\n",
        "#model = tf.keras.models.Sequential([\n",
        "#tf.keras.layers.Rescaling(1. / 255, input_shape=(height, width, 3)),\n",
        "##tf.keras.layers.Input(shape=(height,width,3)),\n",
        "##tf.keras.layers.RandomFlip(\"horizontal\")\n",
        "##tf.keras.layers.RandomRotation(0.2)\n",
        "##tf.keras.layers.RandomContrast(0.5, 2)\n",
        "##tf.keras.layers.RandomCrop(height, width, 3)\n",
        "##tf.keras.layers.RandomZoom(.5, .2)\n",
        "#tf.keras.layers.Conv2D(filters=96, kernel_size=11, strides=4, padding='valid', activation='relu'),\n",
        "#tf.keras.layers.MaxPool2D(pool_size=3, strides = 2, padding='valid'),\n",
        "#tf.keras.layers.Conv2D(filters=256, kernel_size=5, padding=\"same\", activation='relu'),\n",
        "#tf.keras.layers.MaxPool2D(pool_size=3, strides = 2, padding='valid'),\n",
        "#tf.keras.layers.Conv2D(filters=384, kernel_size=3, padding=\"same\", activation='relu'),\n",
        "#tf.keras.layers.Conv2D(filters=384, kernel_size=3, padding=\"same\", activation='relu'),\n",
        "#tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding=\"same\", activation='relu'),\n",
        "#tf.keras.layers.MaxPool2D(pool_size=3, strides = 2, padding='valid'),\n",
        "#tf.keras.layers.Flatten(),\n",
        "##tf.keras.layers.Dense(4096,activation=\"relu\"),\n",
        "##tf.keras.layers.Dense(4096,activation=\"relu\"),\n",
        "#tf.keras.layers.Dense(1000,activation=\"relu\"),\n",
        "#tf.keras.layers.Dense(196,activation=\"softmax\"),\n",
        "#])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lzkhuxmi_6gY",
        "outputId": "1dfee1c1-dcca-4bdd-dc61-542df2e3890e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling (Rescaling)       (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " random_flip (RandomFlip)    (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " random_rotation (RandomRota  (None, 256, 256, 3)      0         \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " random_contrast (RandomCont  (None, 256, 256, 3)      0         \n",
            " rast)                                                           \n",
            "                                                                 \n",
            " random_zoom (RandomZoom)    (None, 256, 256, 3)       0         \n",
            "                                                                 \n",
            " random_brightness (RandomBr  (None, 256, 256, 3)      0         \n",
            " ightness)                                                       \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 256, 256, 32)      896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256, 256, 32)     128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 128, 128, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 128, 128, 64)      18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 128, 128, 64)     256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 64, 64, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 64, 64, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 64, 64, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 32, 32, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 32, 32, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 32, 32, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 16, 16, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 16, 16, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 16, 16, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 8, 8, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 8, 8, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 4, 4, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 196)               803012    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,375,556\n",
            "Trainable params: 2,373,572\n",
            "Non-trainable params: 1,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dFWOMyaHkUX5"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from datetime import datetime\n",
        "from packaging import version\n",
        "\n",
        "import os\n",
        "\n",
        "run_name=\"BetterAugmentation\"\n",
        "\n",
        "logs = \"logs/\" + run_name + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs, profile_batch=(64))\n",
        "\n",
        "#tf.config.optimizer.set_jit(True) enables auto-clustering XLA https://www.tensorflow.org/xla#auto-clustering\n",
        "#print(tf.config.optimizer.get_jit())\n",
        "\n",
        "#Gets an error: \n",
        "#CUDNN_STATUS_INTERNAL_ERROR\n",
        "#in tensorflow/stream_executor/cuda/cuda_dnn.cc(4369): 'status'\n",
        "#\t [[{{node cluster_3_1/xla_run}}]] [Op:__inference_train_function_6519]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, start_from_epoch=40) # start_from_epoch=50 Missing feature in ts2.10, available in ts2.11+\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "        initial_learning_rate=0.001,\n",
        "        decay_steps=10000,\n",
        "        decay_rate=0.9)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "       filepath='./weights/cp-{epoch:04d}.ckpt',\n",
        "        save_weights_only=True,\n",
        "        save_freq='epoch')\n",
        "\n",
        "#Sparese is better than normal cross entropy in our case https://stats.stackexchange.com/questions/326065/cross-entropy-vs-sparse-cross-entropy-when-to-use-one-over-the-other\n",
        "model.compile(optimizer=tf.keras.optimizers.experimental.SGD(learning_rate=0.01,momentum=0.9),loss='sparse_categorical_crossentropy' ,metrics=['accuracy']) \n",
        "\n",
        "history = model.fit(x = cars_train, validation_data = cars_test, epochs = 500, callbacks=[earlystop_callback, tboard_callback, cp_callback], batch_size=batch_size, verbose=1)\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PeVzteONGJK",
        "outputId": "b791056e-41ed-4b64-e61d-c18375e56a43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "227/227 [==============================] - 310s 1s/step - loss: 7.6496 - accuracy: 0.0044 - val_loss: 5.9998 - val_accuracy: 0.0088\n",
            "Epoch 2/500\n",
            "227/227 [==============================] - 268s 1s/step - loss: 5.9259 - accuracy: 0.0062 - val_loss: 5.3948 - val_accuracy: 0.0075\n",
            "Epoch 3/500\n",
            "227/227 [==============================] - 272s 1s/step - loss: 5.4675 - accuracy: 0.0057 - val_loss: 5.3077 - val_accuracy: 0.0069\n",
            "Epoch 4/500\n",
            "227/227 [==============================] - 275s 1s/step - loss: 5.3438 - accuracy: 0.0054 - val_loss: 5.2909 - val_accuracy: 0.0044\n",
            "Epoch 5/500\n",
            "227/227 [==============================] - 268s 1s/step - loss: 5.3001 - accuracy: 0.0066 - val_loss: 5.2843 - val_accuracy: 0.0088\n",
            "Epoch 6/500\n",
            "227/227 [==============================] - 267s 1s/step - loss: 5.2868 - accuracy: 0.0065 - val_loss: 5.2790 - val_accuracy: 0.0088\n",
            "Epoch 7/500\n",
            "115/227 [==============>...............] - ETA: 2:08 - loss: 5.2791 - accuracy: 0.0068"
          ]
        }
      ]
    }
  ]
}